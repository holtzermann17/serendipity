\section{Serendipity in computational systems} \label{sec:computational-serendipity}

The 13 facets of serendipity from Section \ref{sec:literature-review} specify the
conditions and preconditions that are conducive to serendipitous
discovery.  Section \ref{sec:our-model}
distilled these elements into a computational model,
culminating in a method for evaluating computational
serendipity in Section \ref{specs-overview}.

\citeA{pease2013discussion} used an earlier variant these criteria to
analyse three examples of potentially serendipitous behaviour: dynamic
investigation problems, model generation, and poetry flowcharts.
Three additional examples are discussed below using our revised
criteria.  As Campbell \citeyear{campbell2005serendipity} writes,
``serendipity presupposes a smart mind,'' and these examples suggest
potential directions for further work in computational intelligence.

Before describing these examples, as a baseline, we introduce the
notion of \emph{minimally serendipitous systems}.  According to our
standards, there are various ways to achieve a result with little or
no serendipity: if the observation was likely, if further developments
happened with little skill, and if the the value of the result was
low, then we would not say the outcome was serendipitous.  We would be
prepared to attribute ``minimal serendipity'' to cases where the
observation was \emph{moderately} likely, \emph{some} skill or effort
was involved, and the result was only \emph{fairly good}.  However,
for computational systems, if most of the skill involved lies with the
user, then there is little reason to call the system's operation
serendipitous -- even if it consistently does its job very well.  For
example, machines can learn to recognise or approximate certain types
of patterns, but it is surprising when a computational system
independently finds an entirely new kind of pattern.  Furthermore, the
position of the evaluator is important: a spell-checking system might
suggest a particularly fortuitous substitution, but we would not
expect the spell-checker to know when it was being clever.  In such a
case, we may say serendipity has occurred, but not that we have a
serendipitous system.

%% If the system learns an $N$th fact or
%% If applied to a system which could be described as minimally
%% serendipitous at best, and perhaps not at all serendipitous, does our
%% model identify the lack or presence of serendipity?  
%% %% As example, a spellchecker
%% %% program identifies spelling errors in text input and optionally can
%% %% correct spelling automatically. The only situation we can conceive of
%% %% where serendipity could possibly occur is tenuous; perhaps a suggested
%% %% correction may be incorrect, but may lead the user to interpret the
%% %% correction in an unexpected way. In all other aspects that we have
%% %% considered, spellchecker software would be a decidedly unlikely
%% %% candidate for harbouring serendipitous opportunities.  
%% Traditional spellchecker programs could be said to have a
%% \textbf{prepared mind}, in that they are constructed with internal
%% dictionaries with which to check spelling and ways of deciding what a
%% misspelled word might be.  Given our above discussion of how the
%% system might be serendipitous, the \textbf{serendipity trigger} could
%% be seen as the user misspelling a word and the system suggesting
%% alternative possibilities that the user had not previously conceived.
%% However, the \textbf{bridge} from trigger to serendipitous result (if
%% any) would have been built by the user, not by the system.  With
%% adaptive context-aware text completion tools, we can imagine a
%% ``Cyrano de Bergero'' effect in which the machine finds a
%% serendipitous bridge and offers the \textbf{result} to the user.
%% However, the current generation of text completion tools are known
%% more for infelicities than for exceptional wit.

\subsection{Case Study: Evolutionary music improvisation} \label{sec:priorart}

\citeA{jordanous10} reported a computational jazz improvisation system using genetic algorithms. Genetic algorithms, and evolutionary computing more generally, could encourage computational serendipity. We examine Jordanous's system (later given the name {\sf GAmprovising} \cite{jordanous:12}) as a case study for evolutionary computing in the context of our model of computational serendipity: to what extent does {\sf GAmprovising} model serendipity?

{\sf GAmprovising} uses genetic algorithms to evolve a population of \emph{Improvisors}. Each Improvisor is able to randomly generate music based on various parameters such as the range of notes to be used, preferred notes, rhythmic implications around note lengths and other musical parameters \cite<see>{jordanous10}. These parameters are what defines the Improvisor at any point in the system's evolution. After a cycle of evolution, each Improvisor is evaluated via a fitness function based on Ritchie's \citeyear{ritchie07} criteria for creativity.  This model relies on user-supplied ratings of the novelty and appropriateness of the music produced by the Improvisor to calculate 18 criteria that collectively indicate how creative the system is.  The most successful Improvisors (according to this fitness function) are used to seed a new generation of Improvisors, through crossover and mutation operations.

The {\sf GAmprovising} system can be said to have a \textbf{prepared mind} through its background knowledge of what musical concepts to embed in the Improvisors and the evolutionary abilities to evolve Improvisors. A potential \textbf{serendipity trigger} comes from the combination of the mutation and crossover operations previously employed in the genetic algorithm, and the user input feeding into the fitness function to evaluate produced music. A \textbf{bridge} is built to new results through the creation of new Improvisors. The \textbf{results} are the various musical improvisations produced by the fittest Improvisors (as well as, perhaps, the parameters that have been considered fittest).

The likelihood of serendipitous evolution is greatly enhanced by the use of random mutation and crossover operations within the genetic algorithm, which increase the diversity of the search space covered by the system during evolution.  The \textbf{chance} of encountering any particular pair of Improvisor and user evaluation is vanishingly low, given the massive dimensions of this search space.  The evolution of the population of Improvisors could be described as \textbf{curiosity} about how to satisfy the musical tastes of a particular human user who identifies certain Improvisors as interesting.  The system's \textbf{sagacity} corresponds to the likelihood that the user will appreciate a given Improvisor's music (or similar music) over time.  One challenge here is that the tastes of the user may change.  The \textbf{value} of the generated results is maximised by employing a fitness function.

Evolutionary systems such as {\sf GAmprovising} necessarily operate in a \textbf{dynamic world} which is evolving continuously and that must, in particular, take into account the evolution of the user's tastes. \textbf{Multiple contexts} arise from  the user changing their preferences over time and through the possibility of having multiple users evaluate the musical output.  This variant version of the system is not yet implemented, but would be occupied with the more complex problem of satisfying multiple different users' preferences simultaneously.  Moving to a more complex problem domain would require the system to be curious about more than one user at a time, and require greater sagacity if the system is to successfully satisfy multiple tastes.  \textbf{Multiple tasks} are carried out by the system including evolution of Improvisors, generation of music by individual Improvisors, capturing of user ratings of a sample of the Improvisors' output, and fitness calculations.  \textbf{Multiple influences} are captured through the various combinations of parameters that could be set and the potential range of values for each parameter. 
%% Table \ref{caseStudies} summarizes how serendipity in such a system can be described in terms of our model.

\subsection{Case Study: Next-generation recommender systems}
% Stress distinction between serendipity on the system- vs. serendipity on the user's side.
As discussed in Section \ref{sec:related}, recommender systems are one
of the primary contexts in computing where serendipity is considered. Most discussions of serendipity in recommender systems focus on suggesting items to a user that will be likely to introduce new ideas that are unexpected, but close to what the user is already interested in. A recommendation of this type will be called (possibly \mbox{pseudo-)serendipitous}. As we noted, these systems mostly focus on supporting discovery, but some architectures also seem to take account of invention, such as the Bayesian methods surveyed in Chapter 3 of \citeNP{shengbo-guo-thesis}. Recommender systems \emph{stimulate} serendipitous discovery, by \emph{simulating} when this is likely to occur. In respect to related work, we therefore have to distinguish serendipity on the the user side from serendipity in the system. 

Current research in this area focuses on the first aspect and tries to find and assess \textbf{serendipity triggers} by exploiting patterns in the search space. For example, \citeA{Herlocker2004} as well as \citeA{Lu2012} associate less popular items with high unexpectedness. Clustering is also frequently used to discover latent structures in the search space. For example, \citeA{Kamahara2005} partition users into clusters of common interest, while \citeA{Onuma2009} as well as \citeA{Zhang2011} perform clustering on both users and items. %\citeA{Oku2011} allow the user to select two items in order to mix their features. in a sort of conceptual blend.

Note that in the course of evolution of these and other systems it is generally the system's developers who plan and perform adaptations: even in the Bayesian case, the system has limited autonomy. Nevertheless, the impetus to develop increasingly autonomous recommender systems is present, especially in complex domains where hand-tuning is either very cost-intensive or infeasible.  With this challenge in mind, we investigate how serendipity could be achieved on the system side, and potentially be reflected back to the user. In terms of our model, current systems have at least the makings of a \textbf{prepared mind}, comprising both a user- and a domain model, both of which can be updated dynamically. User behaviour (e.g.~following up on certain recommendations) may serve as a \textbf{serendipity trigger} for the system, and change the way it makes recommendations in the future. A \textbf{bridge} to a new kind of recommendation may be found by pattern matching, and especially by looking for exceptional cases: when new elements are introduced into the domain which do not cluster well, or different clusters appear in the user model that do not have obvious connections between them. The intended outcome of recommendations depends on the organisational mission, and can in most cases be situated between making money and empowering the user. The serendipitous \textbf{result} on the system side would be learning a new approach that helps to address these goals.

The imperfect knowledge about the user's preferences and interests represents a main source of \textbf{chance}. Combined with the ability to learn, \textbf{curiosity} could be described as the urge to make recommendations specifically for the purposes of finding out more about users, possibly to the detriment of other metrics over the short term. Measures of \textbf{sagacity} would relate to the system's ability to draw useful inferences from user behaviour.  For example, the system might decide to initiate an A/B test to decide how a novel recommendation strategy influences conversion.  The \textbf{value} of recommendation strategies can be measured in terms of traditional business metrics or other organisational objectives.

Recommender systems have to cope with a \textbf{dynamic world} of changing user preferences and a changing collection of items to recommend.  A dynamic environment which nevertheless exhibits some degree of regularity represents a precondition for useful A/B testing.  As mentioned above the primary \textbf{(multiple) contexts} are the user model and the domain model. A system matching the description here would have \textbf{multiple tasks}: making useful recommendations, generating new experiments to learn about users, and building new models. Such a system could avail itself of \textbf{multiple influences} related to
experimental design, psychology, and domain understanding.

\subsection{Case Study: Automated flowchart assembly}

\textbf{serendipity triggers} ...
\textbf{prepared mind} ...
\textbf{bridge} ...
\textbf{result} ...

\textbf{chance} ...
\textbf{curiosity} ...
\textbf{sagacity} ...
\textbf{value} ...

\textbf{dynamic world} ...
\textbf{multiple contexts} ...
\textbf{multiple tasks} ...
\textbf{multiple influences} ...


\afterpage{\clearpage}
\begin{table}[p]
{\centering \renewcommand{\arraystretch}{1.5}
\footnotesize
\begin{tabular}{p{.7in}@{\hspace{.1in}}p{1.9in}@{\hspace{.1in}}p{1.9in}}
\multicolumn{1}{c}{} & \multicolumn{1}{c}{\textbf{Evolutionary music systems}} & \multicolumn{1}{c}{\textbf{Next Gen.~Recommender systems}} \\[-.1in]
\multicolumn{1}{l}{\em Components} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} \\
\cline{2-3}
\textbf{Serendipity trigger} & Previous evolutionary operations together with user input & Input from user behaviour \\
% \cline{2-3}
\textbf{Prepared mind} & Musical knowledge, evolution mechanisms & Through user/domain model \\
% \cline{2-3}
\textbf{Bridge}  & Creation of newly-evolved Improvisors & Elements identified outside clusters \\
% \cline{2-3}
\textbf{Result} & Music generated by fittest Improvisors& Dependent on organisation goals \\ \cline{2-3}
\multicolumn{1}{l}{\em Dimensions} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} \\
\cline{2-3}
\textbf{Chance} & If discovered in huge search space & Through imperfect knowledge/if learning from user behaviour \\
% \cline{2-3}
\textbf{Curiosity} & Aiming to have a particular user take note of an Improvisor & Making unusual recommendations \\
% \cline{2-3}
\textbf{Sagacity} & User appreciation of Improvisor over time & Updating recommendation model after user behaviour \\
% \cline{2-3}
\textbf{Value} & Via fitness function (as a proxy measure of creativity) & As per business metrics/objectives \\
\cline{2-3}
\multicolumn{1}{l}{\em Factors} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} \\
\cline{2-3}
\textbf{Dynamic world}  & Continuous computational evolution and changes in user tastes& As precondition for testing system's influences on user behaviour\\
%\cline{2-3}
\textbf{Multiple contexts} & Multiple users' opinions would change what the system is curious about and require greater sagacity & User model and domain model\\
% \cline{2-3}
\textbf{Multiple tasks} & Evolving Improvisors, generating music, collecting user input, fitness calculations & Making recommendations, learning from users, updating models \\
% \cline{2-3}
\textbf{Multiple influences} & Through various musical parameter combinations& Experimental design, psychology, domain understanding\\
\cline{2-3}
\end{tabular}
\par}
\normalsize
\bigskip

\caption{Summary: applying our computational serendipity model to two case studies\label{caseStudies}}
\end{table}%

\subsection{Summary}

Table \ref{caseStudies} summarises how the components, dimensions and
factors of our model of serendipity can be mapped to evolutionary
music systems and the class of ``next-generation'' recommender systems
discussed above.  These case studies have shown how our model can be
used to highlight the aspects of existing systems that would need to
be developed further to enhance measures of the system's serendipity.
\clearpage

%%%

%%%

% As a general comment, we would say that this is largely how
% \emph{research and development} of recommender systems works, but
% without the same levels of system automony envisioned here.




