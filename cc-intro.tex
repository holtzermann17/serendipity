\section{Serendipity in a computational context} \label{sec:computational-serendipity}

The 13 criteria from Section \ref{sec:literature-review} specify the
conditions and preconditions that are conducive to serendipitous
discovery.  Here, we revisit each of these criteria and briefly
summarise how they can be thought about from a computational point of
view, again focusing on examples.  We then present a thought
experiment that evaluates the ideas described above in the course of
developing a new system design.

% \input{writers-workshop-background-long}

\subsection{Prior partial examples}

\citeA{pease2013discussion} used a somewhat different version of the
SPECS criteria to discuss three examples, related to dynamic
investigation problems, model generation, and poetry flowcharts.  The 

\paragraph{{[}To add: Jazz.{]}}

% \paragraph{{[}To add: HR.{]}}

\paragraph{Recommender systems.} 

As discussed in Section \ref{sec:related}, recommender systems are one
of the primary contexts in computing where serendipity is seen to play
a role.  As we noted, these systems mostly focus on discovery.
Nevertheless, certain architectures that also take account of
invention may match the criteria described by our model.  We draw on
the observation that recommender systems not only aim to
\emph{stimulate} serendipitous discovery for the user: they also have
the task of \emph{simulating} when this is likely to occur.

A recommendation is typically provided if the system suspects that the
item will be likely to introduce ideas that are close to what the user
knows, but that will be unexpected.  In other words, the system aims
to stimulate serendipity for the user. For example, a museum
recommender service might suggest a colourful medieval painting to a
user who seems to like colourful paintings by the modern artist Keith
Haring.  User behaviour (e.g.~following up on these recommendations)
is outside of the direct control of the system and may serve as a
\textbf{serendipity trigger}, and change the way it makes
recommendations in the future.  The system has a \textbf{prepared
  mind}, including both a \emph{user model} and a \emph{domain model},
both of which can be updated dynamically.  The connections through
which recommendations are made usually happen when the system notices
that elements of the domain have something in common via clustering or
faceting.  A \textbf{bridge} to a new kind of recommendation may be
found if new elements are introduced into the domain which do not
cluster well, or if the user appears to know about different clusters
that do not have obvious connections between them.  The intended
outcome of recommendations depend on the organisational mission
e.g.~to make money, to provide a good user experience, etc.; at the
system level, the serendiptious \textbf{result} would be learning a
new approach that helps to address these goals better.

From the perspective of our model, \textbf{chance} will only have a
significant role if the system has the capacity to learn from user
behaviour.  Indeed, Bayesian methods are used in contemporary recommender systems
(surveyed in Chapter 3 of \citeNP{shengbo-guo-thesis}).  Combined with the ability to learn, \textbf{curiosity}
could be described as the urge to make
``outside-the-box''\footnote{\citeA{abbassi2009getting}.}
recommendations specifically for the purposes of learning more about
users.  The typical commercial perspective on recommendations is
related to the process of ``conversion'' -- turning recommendations
into clicks and clicks into purchases.  Measures of \textbf{sagacity}
would relate to the system's ability to draw inferences from user
behaviour to update the recommendation model.  For example, the system
might do A/B testing to decide how novel recommendation strategies
influences conversion.  The \textbf{value} of new recommendation
strategies can be measured in terms of traditional business metrics or
other organisational objectives.
